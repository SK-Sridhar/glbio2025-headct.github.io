{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SK-Sridhar/glbio2025-headct.github.io/blob/main/Session4/GLBIOSession4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZbZ28CMDZzZ"
      },
      "source": [
        "### **Fundamentals of Head CT Image Processing with SITK**\n",
        "\n",
        "> Manipulating spatial and intensity properties of CT images are a prerequisite for all stuctural neuroimaging research pipelines. This session will introduce the fundamentals of such manipulations using Simple Insights Toolkit (SITK).\n",
        "\n",
        "[Github link to notebook and sample data](https://github.com/SK-Sridhar/glbio2025-headct.github.io)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be used unless direct linking to shared google drive does not work\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# file_path = \"/content/drive/My Drive/GLBIOSession4Data\""
      ],
      "metadata": {
        "id": "NwbwHflYelLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summon The Analytical Gods\n",
        "\n",
        "<img src = \"https://docs.google.com/uc?export=download&id=1UtWX_XSXrMmg43D6KBjAWQx5IDYJ0dDL\" width = \"100 px\" height = \"100 px\">\n",
        "\n"
      ],
      "metadata": {
        "id": "zdiz3FLL0i8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib SimpleITK gdown"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fzEMxgmPEqSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import SimpleITK as sitk # The master of medical image manipulation\n",
        "import pandas as pd # The keeper of tabular wisdom\n",
        "import numpy as np # The essence of numerical sorcery\n",
        "import matplotlib.pyplot as plt # The grand artisan of visual storytelling\n",
        "import copy, gdown, os, re, time #The boring, but important guys"
      ],
      "metadata": {
        "id": "BhWx8Qxj-Vrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qzah-5D2DZzc"
      },
      "source": [
        "Read Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_img_url = 'https://drive.google.com/uc?id=10IH6HtOrO_YxTCI6p8GrGa1FsKDlRfoG'\n",
        "sample_img_name = 'CT PRE CONTRAST 5MM STD.nii'\n",
        "sample_img_save_path = os.path.join('/content', sample_img_name)\n",
        "\n",
        "#reference image/template\n",
        "ref_img_url = 'https://drive.google.com/uc?id=1BSF8CjCE1Zuvn0wvtydKSCzcG650hmJE'\n",
        "ref_img_name = 'TemplateCtElderly.nii.gz'\n",
        "ref_img_save_path = os.path.join('/content', ref_img_name)"
      ],
      "metadata": {
        "id": "1lcnOHWXgfX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download(sample_img_url, sample_img_save_path, quiet=False)"
      ],
      "metadata": {
        "id": "rVbS0DK8hAqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download(ref_img_url, ref_img_save_path, quiet=False)"
      ],
      "metadata": {
        "id": "T6fegSKrpaFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if you have successfully downloaded the sample scans 'CT PRE CONTRAST 5MM STD.nii' and 'TemplateCtElderly.nii.gz'\n",
        "print(os.listdir('/content/'))"
      ],
      "metadata": {
        "id": "BTEmI4KthKV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images in SITK â€“ objects with attributes that describe complete mapping between image data and physical spaces\n",
        "\n",
        "<img src = \"https://docs.google.com/uc?export=download&id=1zPxX9QXZ7l8mq3GSiQrdy6k6dSzrXRQH\" width = \"500 px\" height = \"400 px\">"
      ],
      "metadata": {
        "id": "G5IIqI4a4ab8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fwJQujGeDZzd"
      },
      "outputs": [],
      "source": [
        "#Read in sample image (CT negative)\n",
        "img = sitk.ReadImage('/content/CT PRE CONTRAST 5MM STD.nii')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LHT5DiliDZzd"
      },
      "outputs": [],
      "source": [
        "#Access value in a particular location (i, j, k)\n",
        "print(img.GetPixel((50,29,14)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpVDdOnsDZzh"
      },
      "outputs": [],
      "source": [
        "#Set value\n",
        "img.SetPixel((50, 29, 14), 1)\n",
        "#Check set value\n",
        "print(img.GetPixel((50,29,14)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reset value\n",
        "img.SetPixel((50, 29, 14), -3024)"
      ],
      "metadata": {
        "id": "V0ZQsNji_msw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fe1XbtkoDZzi"
      },
      "outputs": [],
      "source": [
        "#Dimensions of the image\n",
        "img.GetSize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "KqR9ugLgDZzi"
      },
      "outputs": [],
      "source": [
        "#what physical distance does one increment in image coordinates correspond to?\n",
        "img.GetSpacing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2mCHHloDZzi"
      },
      "outputs": [],
      "source": [
        "#How do the image's axes map to physical axes?\n",
        "#Nifti images use the RAS convention\n",
        "np.array(img.GetDirection()).reshape(3,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_1KNavmDZzj"
      },
      "outputs": [],
      "source": [
        "#Where is the origin to the world/physical coordinates system?\n",
        "img.GetOrigin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_WJ8SV1DZzj"
      },
      "outputs": [],
      "source": [
        "#Moving from world/physical coordinates to image coordinates\n",
        "print(img.TransformPhysicalPointToContinuousIndex(img.GetOrigin()))\n",
        "\n",
        "print(img.TransformPhysicalPointToContinuousIndex([x + y for x,y in zip(img.GetOrigin(), img.GetSpacing())]))\n",
        "\n",
        "print(img.TransformPhysicalPointToContinuousIndex([x + 3*y for x,y in zip(img.GetOrigin(), img.GetSpacing())]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "mq39G9yCDZzj"
      },
      "outputs": [],
      "source": [
        "#Moving from image to world coordinates\n",
        "print(img.TransformContinuousIndexToPhysicalPoint((0,0,0))) #notice that this corresponds to the origin\n",
        "\n",
        "print(img.TransformContinuousIndexToPhysicalPoint((1,1,1)))\n",
        "\n",
        "print(img.TransformContinuousIndexToPhysicalPoint((2,2,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zr5HYDVDZzj"
      },
      "source": [
        "###### Accessing the image as a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nheD9ipkDZzj"
      },
      "outputs": [],
      "source": [
        "img_arr = sitk.GetArrayFromImage(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "U71WFCUzDZzj"
      },
      "outputs": [],
      "source": [
        "img_arr.shape, img.GetSize() #note how the dimensions are transposed as compared to the image object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "pA9DFXkDDZzj"
      },
      "outputs": [],
      "source": [
        "plt.hist(np.unique(img_arr).flatten())\n",
        "plt.xlabel('Hounsfield Units')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "skA2BDHXDZzj",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "plt.imshow(img_arr[img_arr.shape[0]//2, :, :], cmap = 'gray')\n",
        "plt.show()\n",
        "#Windowing the image to 0 - 100 HU for better visual contrast\n",
        "img_arr_win = np.where((img_arr < 0)|(img_arr > 100), 0, img_arr)\n",
        "plt.imshow(img_arr_win[img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "plt.show()\n",
        "#Flipped the row order for up-right visualization\n",
        "plt.imshow(img_arr_win[img_arr_win.shape[0]//2, ::-1, :], cmap = 'gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rigid transformations"
      ],
      "metadata": {
        "id": "LozDYCMBLmIF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWMejB5KDZzk"
      },
      "source": [
        "Translation use case: Center-align two images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPG1Mmg3DZzk"
      },
      "outputs": [],
      "source": [
        "#Read in the reference image (stored at ref_img_path) below\n",
        "ref_img = sitk.ReadImage('/content/TemplateCtElderly.nii.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN_3HQLYDZzk"
      },
      "outputs": [],
      "source": [
        "#Infer the centers of the sample and reference images, by converting the center of the image array to world coordinates\n",
        "img_arr_cen = [x//2 for x in img_arr.shape[::-1]] #get image center point, notice how image dimensions are flipped\n",
        "img_center =  img.TransformContinuousIndexToPhysicalPoint(img_arr_cen)#transform image center to physical center"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ref_arr =  sitk.GetArrayFromImage(ref_img) #get reference image array\n",
        "ref_arr_cen =  [x/2 for x in ref_img.GetSize()] #get reference image center point\n",
        "ref_center =  ref_img.TransformContinuousIndexToPhysicalPoint(ref_arr_cen)#transform image center to physical center"
      ],
      "metadata": {
        "id": "a9_ivEc55gV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_img.TransformContinuousIndexToPhysicalPoint(ref_arr_cen), ref_img.TransformContinuousIndexToPhysicalPoint([x/2 for x in ref_img.GetSize()])"
      ],
      "metadata": {
        "id": "qyUliLDvY5a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "gNPHfc8kDZzk"
      },
      "outputs": [],
      "source": [
        "print(img_center, ref_center)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V7oMktLDZzk"
      },
      "outputs": [],
      "source": [
        "#Calculate the translation required to move the sample image to align with the center of the reference image\n",
        "translation = [(x-y) for x,y in zip(img_center, ref_center)]\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3hA1EdiDZzk"
      },
      "outputs": [],
      "source": [
        "def translate_resample(img, translation, dimension = 3):\n",
        "    translation_transform = sitk.AffineTransform(dimension)\n",
        "    #Notice that the image center coordinates are derived by flipping the halved size\n",
        "    translation_transform.SetCenter(img.TransformContinuousIndexToPhysicalPoint([x//2 for x in img.GetSize()[::-1]]))\n",
        "    translation_transform.SetTranslation(translation)\n",
        "\n",
        "    #Get physical boundaries of image\n",
        "    extreme_points = [img.TransformIndexToPhysicalPoint((0,0,0)),\n",
        "                  img.TransformIndexToPhysicalPoint((img.GetWidth(),0,0)),\n",
        "                  img.TransformIndexToPhysicalPoint((img.GetWidth(),img.GetHeight(),0)),\n",
        "                  img.TransformIndexToPhysicalPoint((0,img.GetHeight(),0)),\n",
        "                  img.TransformIndexToPhysicalPoint((0,0,img.GetDepth())),\n",
        "                  img.TransformIndexToPhysicalPoint((img.GetWidth(),0,img.GetDepth())),\n",
        "                  img.TransformIndexToPhysicalPoint((img.GetWidth(),img.GetHeight(),img.GetDepth())),\n",
        "                  img.TransformIndexToPhysicalPoint((0,img.GetHeight(),img.GetDepth()))]\n",
        "\n",
        "    #Derive the translated locations of the boundary points, notice how the inverse of the translation transform is used.\n",
        "    #In SITK, transformations are applied from\n",
        "    inv_transform = translation_transform.GetInverse()\n",
        "\n",
        "    extreme_points_transformed = [inv_transform.TransformPoint(pnt) for pnt in extreme_points]\n",
        "    min_x = min(extreme_points_transformed)[0]\n",
        "    min_y = min(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "    min_z = min(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "    max_x = max(extreme_points_transformed)[0]\n",
        "    max_y = max(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "    max_z = max(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "\n",
        "    output_origin = [min_x, min_y, min_z]\n",
        "\n",
        "\n",
        "    output_spacing = img.GetSpacing()\n",
        "    output_direction = [1,0,0,0,1,0,0,0,1]\n",
        "\n",
        "    #Define the resample function with a desired interpolator\n",
        "\n",
        "    translated_img = sitk.Resample(img, img.GetSize(), translation_transform, sitk.sitkLinear, output_origin,\n",
        "                               output_spacing, output_direction)\n",
        "\n",
        "    return translated_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated_img = translate_resample(img, translation, dimension = 3)\n",
        "translated_img_arr = sitk.GetArrayFromImage(translated_img)"
      ],
      "metadata": {
        "id": "J8Jg67052OID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if your goal of center aligning the sample image to the reference image is achieved\n",
        "print(translated_img.TransformContinuousIndexToPhysicalPoint([x//2 for x in translated_img.GetSize()]))\n",
        "\n",
        "print(ref_center)"
      ],
      "metadata": {
        "id": "dCAWS077CJTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Translation should not affect values in the image array. Why is this not so?\n",
        "(img_arr == translated_img_arr).all()"
      ],
      "metadata": {
        "id": "r2ZKu9CBCQyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_img.GetDirection(), img.GetDirection()"
      ],
      "metadata": {
        "id": "iMnCff7h2cbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recall that this is a NIfTI image, which uses the RAS convention system, meaning we move anterior as the y coordinate\n",
        "#increases, and move right as the x coordinate increases. Notice there is some extra-cranial tissue on the left side of\n",
        "#the original image, which is going to be interpreted as the right side of the patient's head in the translated image."
      ],
      "metadata": {
        "id": "J_fvdrbq7sLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_img_arr_win = np.where((translated_img_arr < 0) | (translated_img_arr > 100), 0 , translated_img_arr)\n",
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 2, nrows = 1)\n",
        "ax[0].imshow(img_arr_win[img_arr_win.shape[0]//2,:,:], cmap = 'gray')\n",
        "ax[1].imshow(translated_img_arr_win[translated_img_arr.shape[0]//2,:,:], cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FJ4piusQPy6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Can we just set the direction explicitly?\n",
        "translated_img.SetDirection([1,0,0,0,-1,0,0,0,1])"
      ],
      "metadata": {
        "id": "svw9x0Y-Cmvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_img_arr = sitk.GetArrayFromImage(translated_img)\n",
        "(img_arr == translated_img_arr).all()"
      ],
      "metadata": {
        "id": "hFJ1EUn7Culm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resetting changes only the interpretation of the image's axes, and does not resample the image in the right orientation"
      ],
      "metadata": {
        "id": "BtPBUllKC671"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtORqeEADZzk"
      },
      "outputs": [],
      "source": [
        "def translate_resample_with_original_dc(img, translation, dimension = 3):\n",
        "    \"\"\" Copy the function \"translate_resample\" here and manipulate it such that the image's direction cosine is preserved following translation\"\"\"\n",
        "\n",
        "    return translated_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEReUC3XDZzk"
      },
      "outputs": [],
      "source": [
        "translated_img_org_dc = translate_resample_with_original_dc(img, translation, dimension = 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if your goal of center aligning the sample image to the reference image is achieved\n",
        "print(translated_img_org_dc.TransformContinuousIndexToPhysicalPoint([x//2 for x in translated_img_org_dc.GetSize()]))\n",
        "\n",
        "print(ref_center)"
      ],
      "metadata": {
        "id": "nJiQL2LK8Sxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HPhsESGDZzl"
      },
      "outputs": [],
      "source": [
        "translated_img_org_dc_arr = sitk.GetArrayFromImage(translated_img_org_dc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtXFbAqmDZzl"
      },
      "outputs": [],
      "source": [
        "(translated_img_org_dc_arr == img_arr).all()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated_img_org_dc.GetDirection()"
      ],
      "metadata": {
        "id": "YV-hbT-dDlX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_img_org_dc_arr_win = np.where((translated_img_org_dc_arr < 0) | (translated_img_org_dc_arr > 100), 0 , translated_img_org_dc_arr)"
      ],
      "metadata": {
        "id": "ET3R7uplQK4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KjJ4maB1DZzp"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 2, nrows = 1)\n",
        "ax[0].imshow(img_arr_win[img_arr_win.shape[0]//2,:,:], cmap = 'gray')\n",
        "ax[1].imshow(translated_img_org_dc_arr_win[translated_img_org_dc_arr_win.shape[0]//2,:,:], cmap = 'gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh8__DRTDZzp"
      },
      "source": [
        "Rotation use case: Rotating images and landmarks by prespecified angles (often used in creating augmentated versions of images for deep learning models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Y68RpS4iDZzq"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img_arr_win[img_arr_win.shape[0]//2,:,:], cmap = 'gray')\n",
        "plt.scatter(img_arr_win.shape[1]//2, img_arr_win.shape[2]//2, color = 'white', marker = 'x')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(img_arr_win.shape[2]//2, img_arr_win.shape[1]//2, img_arr_win.shape[0]//2), img_center"
      ],
      "metadata": {
        "id": "XjNYGzDYHRt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz59yXZGDZzq"
      },
      "outputs": [],
      "source": [
        "#How do we apply a 3D rotation to this image?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFQohMs3DZzr"
      },
      "outputs": [],
      "source": [
        "def rotate_resample(image, landmarks, angles, resampling_type = 'linear', dimension = 3):\n",
        "\n",
        "    assert len(angles) == dimension\n",
        "\n",
        "    theta_radians_x, theta_radians_y, theta_radians_z  = np.deg2rad(angles[0]), np.deg2rad(angles[1]), np.deg2rad(angles[2])\n",
        "\n",
        "    transform_x = sitk.AffineTransform(dimension)\n",
        "    transform_x.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())//2.0))\n",
        "\n",
        "    transform_y = sitk.AffineTransform(dimension)\n",
        "    transform_y.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())//2.0))\n",
        "\n",
        "    transform_z = sitk.AffineTransform(dimension)\n",
        "    transform_z.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())//2.0))\n",
        "\n",
        "\n",
        "\n",
        "    matrix_x = np.array([[1.0, 0.0, 0.0],\n",
        "                         [0.0, np.cos(theta_radians_x), -np.sin(theta_radians_x)],\n",
        "                         [0.0, np.sin(theta_radians_x), np.cos(theta_radians_x)]]) #rotation around the x axis\n",
        "\n",
        "    matrix_y = np.array([[np.cos(theta_radians_y), 0.0, np.sin(theta_radians_y)],\n",
        "                         [0.0, 1.0, 0.0],\n",
        "                         [-np.sin(theta_radians_y), 0.0, np.cos(theta_radians_y)]])  #rotation around the y axis\n",
        "\n",
        "    matrix_z = np.array([[np.cos(theta_radians_z), -np.sin(theta_radians_z), 0.0],\n",
        "                         [np.sin(theta_radians_z),  np.cos(theta_radians_z), 0.0],  #rotation around the z axis\n",
        "                         [0.0, 0.0, 1.0]])\n",
        "\n",
        "    matrix_cor = np.array(image.GetDirection()).reshape(3,3)\n",
        "\n",
        "    transform_x.SetMatrix(matrix_x.ravel())\n",
        "    transform_y.SetMatrix(matrix_y.ravel())\n",
        "    transform_z.SetMatrix(matrix_z.ravel())\n",
        "\n",
        "    composite_transform = sitk.CompositeTransform([transform_x, transform_y, transform_z])\n",
        "\n",
        "\n",
        "    extreme_points = [image.TransformIndexToPhysicalPoint((0,0,0)),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),0,0)),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),0)),\n",
        "                      image.TransformIndexToPhysicalPoint((0,image.GetHeight(),0)),\n",
        "                      image.TransformIndexToPhysicalPoint((0,0,image.GetDepth())),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),0,image.GetDepth())),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),image.GetDepth())),\n",
        "                      image.TransformIndexToPhysicalPoint((0,image.GetHeight(),image.GetDepth()))]\n",
        "\n",
        "\n",
        "    inv_transform = composite_transform.GetInverse()\n",
        "\n",
        "    extreme_points_transformed = [inv_transform.TransformPoint(pnt) for pnt in extreme_points]\n",
        "    min_x = min(extreme_points_transformed)[0]\n",
        "    min_y = min(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "    min_z = min(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "    max_x = max(extreme_points_transformed)[0]\n",
        "    max_y = max(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "    max_z = max(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "\n",
        "\n",
        "    landmarks_transformed = inv_transform.TransformPoint(landmarks)\n",
        "\n",
        "    # Use the original spacing\n",
        "    output_spacing = image.GetSpacing()\n",
        "    # Original image's direction\n",
        "    output_direction = image.GetDirection()\n",
        "    #New origin\n",
        "    output_origin = [min_x, max_y, min_z]\n",
        "\n",
        "    output_size = image.GetSize()\n",
        "\n",
        "    if resampling_type == 'linear':\n",
        "        resampler = sitk.sitkLinear\n",
        "    else:\n",
        "        resampler = sitk.sitkBSpline\n",
        "\n",
        "    rotated_image = sitk.Resample(image, output_size, composite_transform, resampler, output_origin, output_spacing,\n",
        "                                  output_direction)\n",
        "\n",
        "    return rotated_image, landmarks_transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdFnmr8-DZzr"
      },
      "outputs": [],
      "source": [
        "rotated_img, landmarks_transformed = rotate_resample(img, img_center, (10, 15, 10))\n",
        "rotated_img_arr = sitk.GetArrayFromImage(rotated_img)\n",
        "rotated_img_arr_win = np.where((rotated_img_arr < 0) | (rotated_img_arr > 100), 0, rotated_img_arr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Also rotate desired landmarks accordingly\n",
        "landmarks_transformed_img_coords = rotated_img.TransformPhysicalPointToContinuousIndex(landmarks_transformed)"
      ],
      "metadata": {
        "id": "VQx-RHPIH3SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "CNaVgZhPDZzr"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 2, nrows = 1)\n",
        "ax[0].imshow(img_arr_win[img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "ax[0].scatter(img_arr_win.shape[1]//2, img_arr_win.shape[2]//2, color = 'white', marker = 'x')\n",
        "ax[1].imshow(rotated_img_arr_win[rotated_img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "ax[1].scatter(landmarks_transformed_img_coords[1], landmarks_transformed_img_coords[0], color = 'white', marker = 'x')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Examine difference in resampled image quality based on the interpolator used, especially in high density focal spots"
      ],
      "metadata": {
        "id": "hHcfC2ASJJE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rotated_img_bspline, _ = rotate_resample(img, img_center, (10, 15, 10), 'bspline')\n",
        "rotated_img_bspline_arr = sitk.GetArrayFromImage(rotated_img_bspline)\n",
        "rotated_img_bspline_arr_win = np.where((rotated_img_bspline_arr < 0) | (rotated_img_bspline_arr > 100), 0, rotated_img_bspline_arr)"
      ],
      "metadata": {
        "id": "xbMxnmCdJMyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 2, nrows = 1)\n",
        "ax[0].imshow(rotated_img_arr_win[rotated_img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "ax[1].imshow(rotated_img_bspline_arr_win[rotated_img_bspline_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "laJ3eS4BJl_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_5Kf-ePDZzs"
      },
      "source": [
        "Scaling use case: Resizing images to required dimensions (often used to meet computational constraints in training deep\n",
        "learning models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fgi4nqsaDZzs"
      },
      "outputs": [],
      "source": [
        "def resize_resample(image, target_size, dimension = 3):\n",
        "\n",
        "    transform = sitk.AffineTransform(dimension)\n",
        "    transform.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())//2.0))\n",
        "    #Notice how an affine transformation is always initialized with the identity matrix\n",
        "    assert (np.array(transform.GetMatrix()).reshape(3,3) == np.eye(dimension)).all()\n",
        "\n",
        "    extreme_points = [image.TransformIndexToPhysicalPoint((0,0,0)),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),0,0)),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),0)),\n",
        "                      image.TransformIndexToPhysicalPoint((0,image.GetHeight(),0)),\n",
        "                      image.TransformIndexToPhysicalPoint((0,0,image.GetDepth())),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),0,image.GetDepth())),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),image.GetDepth())),\n",
        "                      image.TransformIndexToPhysicalPoint((0,image.GetHeight(),image.GetDepth()))]\n",
        "\n",
        "    inv_transform = transform.GetInverse()\n",
        "\n",
        "    extreme_points_transformed = [inv_transform.TransformPoint(pnt) for pnt in extreme_points]\n",
        "    min_x = min(extreme_points_transformed)[0]\n",
        "    min_y = min(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "    min_z = min(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "    max_x = max(extreme_points_transformed)[0]\n",
        "    max_y = max(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "    max_z = max(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "\n",
        "\n",
        "\n",
        "    output_direction = img.GetDirection()\n",
        "    output_origin = [min_x, max_y, min_z]\n",
        "\n",
        "    # Compute resampled spacing based on the target size.\n",
        "    output_spacing = [int(round(x*y/z)) for x,y,z in zip(image.GetSize(), image.GetSpacing(), target_size)]\n",
        "\n",
        "    resampled_image = sitk.Resample(image, target_size, transform, sitk.sitkLinear, output_origin, output_spacing,\n",
        "                                  output_direction)\n",
        "    return resampled_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.GetSize(), img.GetSpacing()"
      ],
      "metadata": {
        "id": "iV-060VtKkL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_size = (256, 256, 100)\n",
        "resized_image = resize_resample(img, target_size, dimension = 3)"
      ],
      "metadata": {
        "id": "gqKZXEelKgPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_image.GetSize(), resized_image.GetSpacing()"
      ],
      "metadata": {
        "id": "zYKzMw02K2El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_image_arr = sitk.GetArrayFromImage(resized_image)\n",
        "resized_image_arr_win = np.where((resized_image_arr < 0) | (resized_image_arr > 100), 0, resized_image_arr)"
      ],
      "metadata": {
        "id": "QucbEJDkLMLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Notice that the central slices do not correspond to each other in the original and resized images\n",
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 2, nrows = 1)\n",
        "ax[0].imshow(img_arr_win[img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "ax[1].imshow(resized_image_arr_win[resized_image_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xu-ribmlLWQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise - find the slice corresponding to the central slice in the original image\n",
        "\n",
        "resized_center = resized_image.TransformPhysicalPointToContinuousIndex()"
      ],
      "metadata": {
        "id": "e9bgv5yoLrGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 2, nrows = 1)\n",
        "ax[0].imshow(img_arr_win[img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "ax[1].imshow(resized_image_arr_win[int(resized_center[2]), :, :], cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VxGoRD7ZMQat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resample_img(image, target_spacing, dimension = 3):\n",
        "\n",
        "    transform = sitk.AffineTransform(dimension)\n",
        "    transform.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())//2.0))\n",
        "    #Notice how an affine transformation is always initialized with the identity matrix\n",
        "    assert (np.array(transform.GetMatrix()).reshape(3,3) == np.eye(dimension)).all()\n",
        "\n",
        "    extreme_points = [image.TransformIndexToPhysicalPoint((0,0,0)),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),0,0)),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),0)),\n",
        "                      image.TransformIndexToPhysicalPoint((0,image.GetHeight(),0)),\n",
        "                      image.TransformIndexToPhysicalPoint((0,0,image.GetDepth())),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),0,image.GetDepth())),\n",
        "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),image.GetDepth())),\n",
        "                      image.TransformIndexToPhysicalPoint((0,image.GetHeight(),image.GetDepth()))]\n",
        "\n",
        "    inv_transform = transform.GetInverse()\n",
        "\n",
        "    extreme_points_transformed = [inv_transform.TransformPoint(pnt) for pnt in extreme_points]\n",
        "    min_x = min(extreme_points_transformed)[0]\n",
        "    min_y = min(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "    min_z = min(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "    max_x = max(extreme_points_transformed)[0]\n",
        "    max_y = max(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "    max_z = max(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "\n",
        "    output_direction = img.GetDirection()\n",
        "    output_origin = [min_x, max_y, min_z]\n",
        "\n",
        "    # Compute resampled size based on the target spacing.\n",
        "    # Remember, the physical dimensions of the images should remain same pre- and post-respacing - img_size x img_spacing = resampled_img_size x resampled_img_spacing\n",
        "    output_size = []\n",
        "\n",
        "    resampled_image = sitk.Resample(image, output_size, transform, sitk.sitkLinear, output_origin, target_spacing,\n",
        "                                  output_direction)\n",
        "    return resampled_image"
      ],
      "metadata": {
        "id": "xunrZuXvmNdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_spacing = (1,1,1)\n",
        "resampled_img = resize_resample(img, target_size, dimension = 3)"
      ],
      "metadata": {
        "id": "k9KCzsEQ-k6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampled_img.GetSize(), resampled_img.GetSpacing()"
      ],
      "metadata": {
        "id": "pAAzyFR6-_3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skewing - Not prominently used in augmentation techniques"
      ],
      "metadata": {
        "id": "MIWVxlt5__2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def skew_resample(image, skew_values, dimension = 3):\n",
        "\n",
        "  skew_transform = sitk.AffineTransform(dimension)\n",
        "  skew_transform.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize()) // 2.0))\n",
        "\n",
        "  skew_matrix = np.eye(dimension)\n",
        "  for i in range(dimension):\n",
        "    for j in range(i + 1, dimension):\n",
        "      skew_matrix[i, j] = skew_values[j - i -1]\n",
        "\n",
        "  skew_transform.SetMatrix(skew_matrix.ravel())\n",
        "\n",
        "\n",
        "  extreme_points = [image.TransformIndexToPhysicalPoint((0,0,0)),\n",
        "                    image.TransformIndexToPhysicalPoint((image.GetWidth(),0,0)),\n",
        "                    image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),0)),\n",
        "                    image.TransformIndexToPhysicalPoint((0,image.GetHeight(),0)),\n",
        "                    image.TransformIndexToPhysicalPoint((0,0,image.GetDepth())),\n",
        "                    image.TransformIndexToPhysicalPoint((image.GetWidth(),0,image.GetDepth())),\n",
        "                    image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),image.GetDepth())),\n",
        "                    image.TransformIndexToPhysicalPoint((0,image.GetHeight(),image.GetDepth()))]\n",
        "\n",
        "  inv_transform = skew_transform.GetInverse()\n",
        "\n",
        "  extreme_points_transformed = [inv_transform.TransformPoint(pnt) for pnt in extreme_points]\n",
        "  min_x = min(extreme_points_transformed)[0]\n",
        "  min_y = min(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "  min_z = min(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "  max_x = max(extreme_points_transformed)[0]\n",
        "  max_y = max(extreme_points_transformed, key=lambda p: p[1])[1]\n",
        "  max_z = max(extreme_points_transformed, key=lambda p: p[2])[2]\n",
        "\n",
        "\n",
        "  output_direction = img.GetDirection()\n",
        "  output_origin = [min_x, max_y, min_z]\n",
        "\n",
        "\n",
        "  output_spacing = img.GetSpacing()\n",
        "  output_size = [int(round((max_x - min_x) / output_spacing[0])),\n",
        "                 int(round((max_y - min_y) / output_spacing[1])),\n",
        "                 int(round((max_z - min_z) / output_spacing[2]))]\n",
        "\n",
        "  resampled_image = sitk.Resample(image, img.GetSize(), skew_transform, sitk.sitkLinear, output_origin, output_spacing,\n",
        "                                output_direction)\n",
        "\n",
        "\n",
        "  return resampled_image"
      ],
      "metadata": {
        "id": "6am75-7bMz4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skewed_image = skew_resample(img, (0.1, 0.2, 0.3))\n",
        "skewed_img_arr = sitk.GetArrayFromImage(skewed_image)\n",
        "skewed_img_arr_win = np.where((skewed_img_arr < 0) | (skewed_img_arr > 100), 0, skewed_img_arr)"
      ],
      "metadata": {
        "id": "l9MhgYs0NNel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 2, nrows = 1)\n",
        "ax[0].imshow(img_arr_win[img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "ax[1].imshow(skewed_img_arr_win[skewed_img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5pQ7fFpjQzDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manipulating density properties - Skull-stripping\n",
        "\n",
        "\n",
        "1.   Smoothening\n",
        "2.   Thresholding\n",
        "3.   Erosion\n",
        "4.   Retain Largest Connected Component\n",
        "5.   Dilate\n",
        "6.   Close holes\n",
        "7.   Apply mask\n",
        "\n"
      ],
      "metadata": {
        "id": "pBnh-Y0w_7GM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggZFleIYDZzv"
      },
      "outputs": [],
      "source": [
        "def gauss_smooth(input_img, sigma):\n",
        "    \"\"\"Returns gaussian smoothed image\"\"\"\n",
        "    pixelID = input_img.GetPixelID()\n",
        "\n",
        "    gaussian = sitk.SmoothingRecursiveGaussianImageFilter()\n",
        "    gaussian.SetSigma(sigma)\n",
        "    smoothed_img = gaussian.Execute(input_img)\n",
        "\n",
        "    caster = sitk.CastImageFilter()\n",
        "    caster.SetOutputPixelType(pixelID)\n",
        "    smoothed_img = caster.Execute(smoothed_img)\n",
        "\n",
        "    return smoothed_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_omL5idDZzv"
      },
      "outputs": [],
      "source": [
        "def threshold_img(input_img, upper_thresh, lower_thresh):\n",
        "    \"\"\"Returns thresholded image mask (0-100 HU)\"\"\"\n",
        "    pixelID = input_img.GetPixelID()\n",
        "    seg = sitk.BinaryThreshold(input_img, lowerThreshold=lower_thresh, upperThreshold=upper_thresh,\n",
        "                               insideValue=1, outsideValue=0)\n",
        "\n",
        "    caster = sitk.CastImageFilter()\n",
        "    caster.SetOutputPixelType(pixelID)\n",
        "    seg = caster.Execute(seg)\n",
        "    return seg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzvkCSvFDZzv"
      },
      "outputs": [],
      "source": [
        "def erode_img(input_img):\n",
        "    \"\"\"Erodes binary mask by 1mm3 \"\"\"\n",
        "    pixelID = input_img.GetPixelID()\n",
        "    eroded_img = sitk.BinaryErode(input_img, (1,1,1), sitk.sitkBall, foregroundValue = 1.0, backgroundValue = 0.0)\n",
        "    caster = sitk.CastImageFilter()\n",
        "    caster.SetOutputPixelType(pixelID)\n",
        "    eroded_img = caster.Execute(eroded_img)\n",
        "    eroded_img.SetSpacing(input_img.GetSpacing())\n",
        "    return eroded_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASNe-jXGDZzv"
      },
      "outputs": [],
      "source": [
        "def keep_largest_cc(input_img):\n",
        "    \"\"\"Returns largest connected component from binary image \"\"\"\n",
        "\n",
        "    pixelID = input_img.GetPixelID()\n",
        "    largestCC_img = sitk.RelabelComponent(sitk.ConnectedComponent(input_img))==1\n",
        "    caster = sitk.CastImageFilter()\n",
        "    caster.SetOutputPixelType(pixelID)\n",
        "    largestCC_img = caster.Execute(largestCC_img)\n",
        "    return largestCC_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgEIQsYvDZzv"
      },
      "outputs": [],
      "source": [
        "def dilate_img(input_img, kernelSize):\n",
        "    \"\"\"Dilates mask by 1mm3\"\"\"\n",
        "    pixelID = input_img.GetPixelID()\n",
        "    dilated_img = sitk.BinaryDilate(input_img, (1,1,1), sitk.sitkBall, foregroundValue = 1.0, backgroundValue = 0.0)\n",
        "    caster = sitk.CastImageFilter()\n",
        "    caster.SetOutputPixelType(pixelID)\n",
        "    dilated_img = caster.Execute(dilated_img)\n",
        "    dilated_img.SetSpacing(input_img.GetSpacing())\n",
        "    return dilated_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p44Zn51dDZzw"
      },
      "outputs": [],
      "source": [
        "def morphology_close(input_img, ):\n",
        "    \"\"\"Closes any holes with spherical 1mm3 kernel\"\"\"\n",
        "    pixelID = input_img.GetPixelID()\n",
        "    closed_img = sitk.BinaryMorphologicalClosing(input_img,\n",
        "                                            (1,1,1))\n",
        "\n",
        "    caster = sitk.CastImageFilter()\n",
        "    caster.SetOutputPixelType(pixelID)\n",
        "    closed_img = caster.Execute(closed_img)\n",
        "    return closed_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2vO5bflDZzw"
      },
      "outputs": [],
      "source": [
        "def skull_strip(input_img, closed_img_mask):\n",
        "    \"\"\"Applies the calculated mask - slice by slice\"\"\"\n",
        "    closed_img_mask_arr = sitk.GetArrayFromImage(closed_img_mask)\n",
        "    input_img_arr = sitk.GetArrayFromImage(input_img)\n",
        "    skull_stripped_arr = np.zeros(input_img_arr.shape)\n",
        "    for pl in range(len(input_img_arr)):\n",
        "        skull_stripped_arr[pl,:,:] = closed_img_mask_arr[pl,:,:]*input_img_arr[pl,:,:]\n",
        "    brain_img = sitk.GetImageFromArray(skull_stripped_arr)\n",
        "    brain_img.SetSpacing(input_img.GetSpacing())\n",
        "    brain_img.SetOrigin(input_img.GetOrigin())\n",
        "    brain_img.SetDirection(input_img.GetDirection())\n",
        "    return brain_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9wq-jmYRDZzw"
      },
      "outputs": [],
      "source": [
        "#Why is windowing not useful in itself for skull-stripping?\n",
        "plt.imshow(img_arr_win[img_arr_win.shape[0]//2,:,:],cmap = 'gray')\n",
        "plt.title('Original Image Windowed')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_POJf4c0DZzx"
      },
      "outputs": [],
      "source": [
        "smoothed_img = gauss_smooth(img, 2)\n",
        "smoothed_img_arr = sitk.GetArrayFromImage(smoothed_img)\n",
        "plt.imshow(smoothed_img_arr[smoothed_img_arr.shape[0]//2,:,:],cmap = 'gray')\n",
        "plt.title('Smoothed image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "EoWbDXbQDZzx"
      },
      "outputs": [],
      "source": [
        "thresh_img = threshold_img(smoothed_img, 100, 0)\n",
        "thresh_img_arr = sitk.GetArrayFromImage(thresh_img)\n",
        "\n",
        "thresh_img_unsmooth = threshold_img(img, 100, 0)\n",
        "thresh_img_arr_unsmooth = sitk.GetArrayFromImage(thresh_img_unsmooth)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 2, nrows = 1)\n",
        "ax[0].imshow(thresh_img_arr[thresh_img_arr.shape[0]//2,:,:],cmap = 'gray')\n",
        "ax[1].imshow(thresh_img_arr_unsmooth[thresh_img_arr_unsmooth.shape[0]//2,:,:],cmap = 'gray')\n",
        "ax[0].set_title('Smoothed and thresholded image')\n",
        "ax[1].set_title('Unsmoothed and thresholded image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for pl in range(10):\n",
        "    plt.imshow(thresh_img_arr[pl,:,:],cmap = 'gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BmCHu88FBMX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "jMdAfMJdDZzx"
      },
      "outputs": [],
      "source": [
        "eroded_img =  erode_img(thresh_img)\n",
        "eroded_img_arr = sitk.GetArrayFromImage(eroded_img)\n",
        "plt.imshow(eroded_img_arr[eroded_img_arr.shape[0]//2 - 2,:,:],cmap = 'gray')\n",
        "plt.title('Eroded image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rDbNf_a-DZzx"
      },
      "outputs": [],
      "source": [
        "#Notice how the lower parts of the skull are significantly disconnected after erosion\n",
        "for pl in range(10):\n",
        "    plt.imshow(eroded_img_arr[pl,:,:],cmap = 'gray')\n",
        "    plt.title('Eroded image')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "-D3FKsimDZzx"
      },
      "outputs": [],
      "source": [
        "largest_cc_img = keep_largest_cc(eroded_img)\n",
        "largest_cc_img_arr = sitk.GetArrayFromImage(largest_cc_img)\n",
        "plt.imshow(largest_cc_img_arr[largest_cc_img_arr.shape[0]//2 - 2,:,:],cmap = 'gray')\n",
        "plt.title('Largest CC')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Rh_jOjtwDZzx"
      },
      "outputs": [],
      "source": [
        "dilated_img =  dilate_img(largest_cc_img, 1)\n",
        "dilated_img_arr = sitk.GetArrayFromImage(dilated_img)\n",
        "plt.imshow(dilated_img_arr[dilated_img_arr.shape[0]//2 - 2,:,:],cmap = 'gray')\n",
        "plt.title('Dilated image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "qRn66K3PDZzx"
      },
      "outputs": [],
      "source": [
        "closed_img_mask = morphology_close(dilated_img)\n",
        "closed_img_arr = sitk.GetArrayFromImage(closed_img_mask)\n",
        "plt.imshow(closed_img_arr[closed_img_arr.shape[0]//2 - 2,:,:],cmap = 'gray')\n",
        "plt.title('Closed image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDIkFcyIDZzx"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 2, nrows = 1)\n",
        "brain_img =  skull_strip(img, closed_img_mask)\n",
        "brain_img_arr = sitk.GetArrayFromImage(brain_img)\n",
        "brain_img_arr_win = np.where((brain_img_arr < 0) | (brain_img_arr > 100), 0, brain_img_arr)\n",
        "ax[0].imshow(brain_img_arr_win[brain_img_arr_win.shape[0]//2,:,:],cmap = 'gray')\n",
        "ax[0].set_title('Brain')\n",
        "ax[1].imshow(img_arr_win[img_arr_win.shape[0]//2,:,:],cmap = 'gray')\n",
        "ax[1].set_title('Windowed Image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Registration with SITK\n",
        "\n",
        "<img src = \"https://docs.google.com/uc?export=download&id=133zcbuUSXQ8wmLcXdBsUJE5TG0QnhL_U\" width = \"500 px\" height = \"275 px\">\n",
        "\n",
        "\n",
        "1.   Bringing images into spatial correspondence\n",
        "2.   Find the spatial mapping (rigid or nonrigid) which optimally maps a\n",
        "     \"moving\" image (input scan) to a \"fixed\" image (reference template)\n",
        "3.   Essentially Solving an optimization problem, once the transformation has\n",
        "     been parameterized.\n",
        "4.   We have to pick a cost function which will give us a sense of how close\n",
        "     the images are getting, as this process usually proceeds in an iterative scheme. Also need a tolerance for the error.\n",
        "5.   Optimizers for these cost functions take the form of the familiar gradient\n",
        "     descent.\n",
        "6.   What are sampling strategies and multi-resolution schemes?\n",
        "7.   What are some pitfalls in registration?\n",
        "8.   Applications of these include - intra and inter-patient scan comparisons,\n",
        "     standard alignment in neurosurgical procedures, radiation therapy.\n",
        "9.   Can even be applied to segmentation.\n",
        "\n",
        "Let us walk through the recommended course of actions and discuss the above points for successful image registration\n",
        "\n"
      ],
      "metadata": {
        "id": "bajlUoXiDVME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How does the template look like? - An \"averaged\" scan\n",
        "ref_img_arr = sitk.GetArrayFromImage(ref_img)\n",
        "ref_img_arr_win = np.where((ref_img_arr < 0) | (ref_img_arr > 100), 0, ref_img_arr)\n",
        "plt.imshow(ref_img_arr_win[ref_img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "05CWFsTOM8tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_img_iso = resample_img(brain_img, [1,1,1], dimension = 3) #isotropic resample"
      ],
      "metadata": {
        "id": "HSeAxJppmtSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_img_iso.GetSpacing()"
      ],
      "metadata": {
        "id": "y9g98dLpm5dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqdwhOskRQB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us center align the input scan to the template to not \"waste\" degrees of freedom provided by the rigid registration\n",
        "brain_img_iso_cen = brain_img_iso.TransformContinuousIndexToPhysicalPoint([x/2 for x in brain_img_iso.GetSize()])\n",
        "translation = [(x-y) for x,y in zip(brain_img_iso_cen, ref_center)]"
      ],
      "metadata": {
        "id": "vLOeX5tHUpW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_img_cen_aligned = translate_resample_with_original_dc(brain_img_iso, translation)"
      ],
      "metadata": {
        "id": "9jBupuCtfC6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_img_cen_aligned.TransformContinuousIndexToPhysicalPoint([x/2 for x in brain_img_cen_aligned.GetSize()]), ref_center"
      ],
      "metadata": {
        "id": "Mwxm2J1KfTjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check directions.\n",
        "brain_img_cen_aligned.GetDirection(), ref_img.GetDirection()"
      ],
      "metadata": {
        "id": "NicMSIm2Rh-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you resample the images to have the same orientation with rotation?\n",
        "\n",
        "<img src = \"https://docs.google.com/uc?export=download&id=1eVQD7CwvawJ6sHROcIo3TiW5l6ihUBXE\" width = \"275 px\" height = \"275 px\">"
      ],
      "metadata": {
        "id": "JkPY70ikSvrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How about flipping?\n",
        "brain_img_cen_aligned_arr = sitk.GetArrayFromImage(brain_img_cen_aligned)\n",
        "brain_img_cen_aligned_arr_win = np.where((brain_img_cen_aligned_arr < 0) | (brain_img_cen_aligned_arr > 100), 0, brain_img_cen_aligned_arr)\n",
        "brain_img_cen_aligned_arr_flipped = brain_img_cen_aligned_arr[:, :, ::-1]\n",
        "brain_img_flipped = sitk.GetImageFromArray(brain_img_cen_aligned_arr_flipped)\n",
        "brain_img_flipped.SetDirection(ref_img.GetDirection())"
      ],
      "metadata": {
        "id": "sq7u-QmZZ1fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_img_flipped.GetDirection(), ref_img.GetDirection()"
      ],
      "metadata": {
        "id": "IYqT4MNVqDw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cast both images to the same pixel type\n",
        "ref_img = sitk.Cast(ref_img, sitk.sitkFloat32)\n",
        "brain_img_flipped = sitk.Cast(brain_img_flipped, sitk.sitkFloat32)"
      ],
      "metadata": {
        "id": "8F0WSMSktKAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rigid_registration(ref_img, moving_img):\n",
        "  #Initialize the rigid transform (translation + rotation)\n",
        "  rigid_transform = sitk.CenteredTransformInitializer(\n",
        "                        ref_img, moving_img, sitk.AffineTransform(3),\n",
        "                        sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
        "                    )\n",
        "\n",
        "  registration = sitk.ImageRegistrationMethod()\n",
        "\n",
        "  #Optimization metric\n",
        "  registration.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
        "\n",
        "  #Set number of random samples and strategies to sample points\n",
        "  registration.SetMetricSamplingStrategy(registration.RANDOM)\n",
        "  registration.SetMetricSamplingPercentage(0.01)\n",
        "\n",
        "  #Set interpolator\n",
        "  registration.SetInterpolator(sitk.sitkLinear)\n",
        "\n",
        "  # Optimizer settings.\n",
        "  registration.SetOptimizerAsRegularStepGradientDescent(\n",
        "      learningRate=1.0,\n",
        "      minStep=1e-4,\n",
        "      numberOfIterations=100,\n",
        "      gradientMagnitudeTolerance=1e-8\n",
        "  )\n",
        "\n",
        "  registration.SetOptimizerScalesFromPhysicalShift()\n",
        "\n",
        "  # Setup for the multi-resolution framework (3 levels)\n",
        "  registration.SetShrinkFactorsPerLevel(shrinkFactors=[4,2,1])\n",
        "  registration.SetSmoothingSigmasPerLevel(smoothingSigmas=[2,1,0])\n",
        "\n",
        "  registration.SetInitialTransform(rigid_transform)\n",
        "\n",
        "  # Execute registration\n",
        "  final_transform = registration.Execute(ref_img, moving_img)\n",
        "\n",
        "  print(f\"Final metric value: {registration.GetMetricValue()}\")\n",
        "  print(f\"Optimizer's stopping condition, {registration.GetOptimizerStopConditionDescription()}\")\n",
        "\n",
        "  # Resample the moving image using the final transform\n",
        "  resampled_moving = sitk.Resample(moving_img, ref_img, final_transform, sitk.sitkLinear, 0.0, ref_img.GetPixelID())\n",
        "\n",
        "  return resampled_moving"
      ],
      "metadata": {
        "id": "zlMIAtlKYGGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampled_moving = rigid_registration(ref_img, brain_img_flipped)"
      ],
      "metadata": {
        "id": "oNUA54ReEbGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampled_moving_arr = sitk.GetArrayFromImage(resampled_moving)\n",
        "resampled_moving_arr_win = np.where((resampled_moving_arr < 0) | (resampled_moving_arr > 100), 0, resampled_moving_arr)"
      ],
      "metadata": {
        "id": "KFwntrMndGx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(resampled_moving_arr), np.max(resampled_moving_arr)"
      ],
      "metadata": {
        "id": "BF2pVfT7ZY5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_img_iso_arr = sitk.GetArrayFromImage(brain_img_iso)\n",
        "brain_img_iso_arr_win = np.where((brain_img_iso_arr < 0) | (brain_img_iso_arr > 100), 0, brain_img_iso_arr)\n",
        "\n",
        "brain_img_flipped_arr = sitk.GetArrayFromImage(brain_img_flipped)\n",
        "brain_img_flipped_arr_win = np.where((brain_img_flipped_arr < 0) | (brain_img_flipped_arr > 100), 0, brain_img_flipped_arr)"
      ],
      "metadata": {
        "id": "lgdkhW2hb2Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (10,20), ncols = 3, nrows = 1)\n",
        "ax[0].imshow(brain_img_flipped_arr_win[brain_img_flipped_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "ax[0].set_title('Moving Image')\n",
        "ax[1].imshow(ref_img_arr_win[ref_img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "ax[1].set_title('Fixed Image')\n",
        "ax[2].imshow(resampled_moving_arr_win[resampled_moving_arr_win.shape[0]//2,:,:],cmap = 'gray')\n",
        "ax[2].set_title('Aligned Image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CMa7uABmetTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(ref_img_arr_win[ref_img_arr_win.shape[0]//2, :, :], cmap = 'gray')\n",
        "plt.imshow(resampled_moving_arr_win[resampled_moving_arr_win.shape[0]//2,:,:],alpha = .75)\n",
        "plt.title('Rigid Registration Results')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9OsjDh7fZUVf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}